{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https_proxy is set as http://127.0.0.1:7890\n",
      "http_proxy is set as http://127.0.0.1:7890\n",
      "HF_ENDPOINT is set as https://hf-mirror.com\n",
      "HF_HUB_ENABLE_HF_TRANSFER is set as 0\n"
     ]
    }
   ],
   "source": [
    "# check env variable\n",
    "def check(VAR):\n",
    "    import os\n",
    "\n",
    "    if VAR in os.environ:\n",
    "        print(f\"{VAR} is set as {os.environ[VAR]}\")\n",
    "\n",
    "\n",
    "def checkVars(VARS):\n",
    "    for VAR in VARS:\n",
    "        check(VAR)\n",
    "\n",
    "\n",
    "VARS = [\"https_proxy\", \"http_proxy\", \"HF_ENDPOINT\", \"HF_HUB_ENABLE_HF_TRANSFER\"]\n",
    "checkVars(VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertModel, BertConfig, BertTokenizer\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/home/twh/code/mtba/asap/data\"\n",
    "useModel = \"google-bert/bert-base-chinese\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cacheDir = \"./cache/\"\n",
    "\n",
    "\n",
    "def get_data_path(dataFile):\n",
    "    return os.path.join(dataDir, dataFile)\n",
    "\n",
    "\n",
    "def get_data(dataFile):\n",
    "    return pd.read_csv(get_data_path(dataFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "状元楼饭店第一次去，因为地理位置优越：在宁波市和义大道高、大、上，里面装修中式，菜是地道的宁波菜，口味纯正，醉泥螺特棒，吃到了小时候的味道，因为去了晚了，在大堂等了一会儿，期间有茶水喝、服务员还与你聊天，到了就餐时生意太好，服务员都是小跑状，服务态度绝对不提速，样样都服务到位，点酒水还耐心的与我们解释，就这样绝对要夸一夸，特别是彭新星、洪继华（看服务牌才知道名字）也给我们宁波市形象增色，状元楼是宁波的一扇窗口，服务员的素质更体现我们宁波人的精神面貌。赞一个\n",
      "Index(['index', 'reviewbody', 'star', 'location_traffic',\n",
      "       'location_distance_from_business_district', 'location_easy_to_find',\n",
      "       'service_wait_time', 'service_waiters_attitude',\n",
      "       'service_parking_convenience', 'service_serving_speed', 'price_level',\n",
      "       'price_cost_effective', 'price_discount', 'environment_decoration',\n",
      "       'environment_noise', 'environment_space', 'environment_cleaness',\n",
      "       'dish_portion', 'dish_taste', 'dish_look', 'dish_recommendation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_sample = get_data(\"train_sample.csv\")\n",
    "# train_sample.head()\n",
    "test_text = train_sample[\"reviewbody\"][0]\n",
    "print(test_text)\n",
    "print(train_sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'review', 'star', 'Location#Transportation', 'Location#Downtown',\n",
      "       'Location#Easy_to_find', 'Service#Queue', 'Service#Hospitality',\n",
      "       'Service#Parking', 'Service#Timely', 'Price#Level',\n",
      "       'Price#Cost_effective', 'Price#Discount', 'Ambience#Decoration',\n",
      "       'Ambience#Noise', 'Ambience#Space', 'Ambience#Sanitary', 'Food#Portion',\n",
      "       'Food#Taste', 'Food#Appearance', 'Food#Recommend'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_set = get_data(\"train.csv\")\n",
    "print(train_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'review', 'star', 'Location#Transportation', 'Location#Downtown',\n",
      "       'Location#Easy_to_find', 'Service#Queue', 'Service#Hospitality',\n",
      "       'Service#Parking', 'Service#Timely', 'Price#Level',\n",
      "       'Price#Cost_effective', 'Price#Discount', 'Ambience#Decoration',\n",
      "       'Ambience#Noise', 'Ambience#Space', 'Ambience#Sanitary', 'Food#Portion',\n",
      "       'Food#Taste', 'Food#Appearance', 'Food#Recommend'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_set = get_data(\"test.csv\")\n",
    "print(test_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(useModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # 分别提取输入文本和标签\n",
    "        self.reviews = self.data[\"review\"].tolist()\n",
    "        # 提取 'star' 及之后所有列作为标签\n",
    "        self.labels = self.data.loc[:, \"star\":].to_numpy()\n",
    "        # 将 'star' 之后所有列的值加2\n",
    "        self.labels[..., 1:] += 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews[idx]\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        # 使用tokenizer编码文本\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors=\"pt\",  # 返回PyTorch tensors格式\n",
    "        )\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"].squeeze(0)  # 去掉批次维度\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 18])\n"
     ]
    }
   ],
   "source": [
    "# compute weights according to the distribution of the labels\n",
    "def compute_weights(data=get_data(\"train.csv\")):\n",
    "    data = data.loc[:, \"Location#Transportation\":] + 2\n",
    "    # compute value frequency for each column\n",
    "    value_freq = data.apply(pd.Series.value_counts)\n",
    "    # normalize the frequency\n",
    "    value_freq = value_freq.div(value_freq.sum(axis=0), axis=1)\n",
    "    # print(value_freq)\n",
    "    # get 1/freq as pytorch tensor\n",
    "    weights = torch.tensor(1 / value_freq.values, dtype=torch.float)\n",
    "    return weights\n",
    "\n",
    "\n",
    "weights = compute_weights().to(device)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ReviewsDataset(dataframe=get_data(\"train.csv\"), tokenizer=tokenizer)\n",
    "test_set = ReviewsDataset(dataframe=get_data(\"test.csv\"), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f24ea4432b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot length distribution of train set and test set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_lengths = [len(review) for review in train_set.reviews]\n",
    "test_lengths = [len(review) for review in test_set.reviews]\n",
    "\n",
    "plt.hist(train_lengths, bins=30, alpha=0.5, label=\"train\")\n",
    "plt.hist(test_lengths, bins=30, alpha=0.5, label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(tensor):\n",
    "    print(tensor.shape)\n",
    "\n",
    "\n",
    "class BertForFineGrainedSentimentClassification(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes_per_aspect, num_aspects, config, enjoy_weights=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes_per_aspect = num_classes_per_aspect\n",
    "        self.num_aspects = num_aspects\n",
    "        self.enjoy_weights = enjoy_weights\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(useModel, config=config)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.scorer = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(config.hidden_size, 1, bias=False),\n",
    "        )\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        if not enjoy_weights:\n",
    "            self.Wa = nn.Parameter(\n",
    "                torch.Tensor(num_aspects, config.hidden_size, config.hidden_size)\n",
    "            )\n",
    "            self.w = nn.Parameter(torch.Tensor(num_aspects, 1, config.hidden_size))\n",
    "            self.Wp = nn.Parameter(\n",
    "                torch.Tensor(num_aspects, config.hidden_size, config.hidden_size)\n",
    "            )\n",
    "            self.Wq = nn.Parameter(\n",
    "                torch.Tensor(num_aspects, num_classes_per_aspect, config.hidden_size)\n",
    "            )\n",
    "            self.bq = nn.Parameter(torch.Tensor(num_aspects, num_classes_per_aspect, 1))\n",
    "        else:\n",
    "            self.aspect = nn.Sequential(\n",
    "                nn.Linear(config.hidden_size, config.hidden_size),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(config.hidden_size, 1),\n",
    "            )\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights for custom layers and parameters\"\"\"\n",
    "        # 初始化Scorer模块\n",
    "        for layer in self.scorer:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_normal_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "        # 初始化自定义参数\n",
    "        nn.init.xavier_normal_(self.Wa)\n",
    "        nn.init.xavier_normal_(self.w)\n",
    "        nn.init.xavier_normal_(self.Wp)\n",
    "        nn.init.xavier_normal_(self.Wq)\n",
    "        nn.init.zeros_(self.bq)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.bert(**inputs)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        # print_shape(sequence_output)\n",
    "        if not self.enjoy_weights:\n",
    "            sequence_output = sequence_output.transpose(1, 2)\n",
    "            # print_shape(sequence_output)\n",
    "            # sequence_output (batch_size, hidden_size, seq_len) ie (B,d,Z)\n",
    "            Ma = torch.einsum(\"Ndd,BdZ->BNdZ\", self.Wa, sequence_output)\n",
    "            # print_shape(Ma)\n",
    "            wMa = torch.einsum(\"Ned,BNdZ->BNeZ\", self.w, Ma).transpose(2, 3)\n",
    "            # print_shape(wMa)\n",
    "            alpha = torch.softmax(wMa, dim=-1)\n",
    "            WpH = torch.einsum(\"Ndd,BdZ->BNdZ\", self.Wp, sequence_output)\n",
    "            # print_shape(WpH)\n",
    "            WpH_alpha = torch.einsum(\"BNdZ,BNZe->BNde\", WpH, alpha)\n",
    "            r = torch.tanh(WpH_alpha)\n",
    "            # print_shape(r)\n",
    "            Wqr = torch.einsum(\"NCd,BNde->BNCe\", self.Wq, r)\n",
    "            # print_shape(Wqr)\n",
    "            # print(Wqr)\n",
    "            # Wqr (B, N, C, e) bq (N, C, e)\n",
    "            yhat = torch.softmax((Wqr + self.bq).squeeze(-1), dim=-1)\n",
    "            # print_shape(yhat)\n",
    "            # print(yhat)\n",
    "\n",
    "        else:\n",
    "            temp = self.aspect(sequence_output)\n",
    "            print_shape(temp)\n",
    "\n",
    "            yhat = None\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Get CLS embedding, which is of shape (batch_size, hidden_size) ie (B,d)\n",
    "        cls_embedding = outputs.pooler_output\n",
    "        # print_shape(cls_embedding)\n",
    "        ghat = self.scorer(cls_embedding).squeeze(-1)\n",
    "        # print_shape(ghat)\n",
    "\n",
    "        return yhat, ghat\n",
    "\n",
    "\n",
    "def loss(yhat, ghat, labels):\n",
    "    # Convert labels to long and ensure the change is kept by assignment\n",
    "    labels = labels.to(torch.long)  # Correction here\n",
    "\n",
    "    # Extract score labels and aspect labels\n",
    "    score_labels = labels[:, 0].float()  # Convert score labels to float for MSE Loss\n",
    "    aspect_labels = labels[:, 1:]  # aspect_labels are already long now\n",
    "\n",
    "    print_shape(aspect_labels)\n",
    "\n",
    "    num_aspects = aspect_labels.size(1)\n",
    "    # print(num_aspects)\n",
    "\n",
    "    # Compute loss for aspect classification\n",
    "    aspect_loss = 0\n",
    "    for i in range(num_aspects):\n",
    "        aspect_loss += nn.CrossEntropyLoss(weight=weights[:, i])(\n",
    "            yhat[:, i, :], aspect_labels[:, i]\n",
    "        )\n",
    "    aspect_loss /= num_aspects\n",
    "\n",
    "    # Initialize MSELoss for score regression and compute loss\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    score_loss = mse_loss(\n",
    "        ghat, score_labels.float()\n",
    "    )  # Make sure score_labels are floats\n",
    "\n",
    "    # Total loss is the sum of aspect and score losses\n",
    "    total_loss = aspect_loss + score_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 18])\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(useModel)\n",
    "\n",
    "model = BertForFineGrainedSentimentClassification(\n",
    "    num_classes_per_aspect=4,\n",
    "    num_aspects=18,\n",
    "    config=config,\n",
    ").to(device)\n",
    "\n",
    "# get a batch of data\n",
    "batch = next(iter(test_loader))\n",
    "inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "labels = batch[\"labels\"].to(device)\n",
    "yhat, ghat = model(inputs)\n",
    "loss = loss(yhat, ghat, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(356, device='cuda:0') 1152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aspect_accuracy': tensor(0.2416, device='cuda:0'),\n",
       " 'score_rmse': tensor(2.6525, device='cuda:0', grad_fn=<SqrtBackward0>)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute_metrics(yhat, ghat, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(yhat, ghat, labels):\n",
    "    # Extract score labels and aspect labels\n",
    "    score_labels = labels[:, 0].float()\n",
    "    aspect_labels = labels[:, 1:]\n",
    "    # print_shape(aspect_labels)\n",
    "\n",
    "    # compute aspect accuracy\n",
    "    aspect_labels[aspect_labels == 0] = -100\n",
    "    valid_label_counts = (aspect_labels != -100).sum()\n",
    "    print(valid_label_counts, 64 * 18)\n",
    "    aspect_accuracy = (\n",
    "        torch.argmax(yhat, dim=-1) == aspect_labels\n",
    "    ).sum() / valid_label_counts\n",
    "\n",
    "    # compute aspect accuracy, ignore\n",
    "    # aspect_preds = torch.argmax(yhat, dim=-1)\n",
    "    # aspect_accuracy = (aspect_preds == aspect_labels).float().mean()\n",
    "\n",
    "    # compute score RMSE\n",
    "    score_rmse = torch.sqrt(torch.mean((ghat - score_labels) ** 2))\n",
    "\n",
    "    return {\"aspect_accuracy\": aspect_accuracy, \"score_rmse\": score_rmse}\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, epochs, load_cache=True):\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    optimizer = AdamW(model.parameters())\n",
    "\n",
    "    if load_cache:\n",
    "        if os.path.exists(os.path.join(cacheDir, \"model.pth\")):\n",
    "            model.load_state_dict(torch.load(os.path.join(cacheDir, \"model.pth\")))\n",
    "        if os.path.exists(os.path.join(cacheDir, \"optimizer.pth\")):\n",
    "            optimizer.load_state_dict(\n",
    "                torch.load(os.path.join(cacheDir, \"optimizer.pth\"))\n",
    "            )\n",
    "\n",
    "    model.train()\n",
    "    global_step = 0  # 初始化全局步数\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {\n",
    "                key: val.to(device) for key, val in batch.items() if key != \"labels\"\n",
    "            }\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            yhat, ghat = model(inputs)\n",
    "            loss = criterion(yhat, ghat, labels)\n",
    "            metrics = compute_metrics(yhat, ghat, labels)\n",
    "            for key, val in metrics.items():\n",
    "                writer.add_scalar(key, val.item(), global_step)  # 使用全局步数\n",
    "            writer.add_scalar(\"batch loss\", loss.item(), global_step)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1  # 更新全局步数\n",
    "\n",
    "        writer.add_scalar(\n",
    "            \"training loss\", running_loss / len(train_loader), global_step\n",
    "        )  # 记录每个epoch的平均损失\n",
    "\n",
    "        # save model and optimizer\n",
    "        torch.save(model.state_dict(), os.path.join(cacheDir, \"model.pth\"))\n",
    "        torch.save(optimizer.state_dict(), os.path.join(cacheDir, \"optimizer.pth\"))\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(useModel)\n",
    "\n",
    "model = BertForFineGrainedSentimentClassification(\n",
    "    num_classes_per_aspect=4,\n",
    "    num_aspects=18,\n",
    "    config=config,\n",
    ").to(device)\n",
    "\n",
    "# train(model, train_loader, loss, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, test_loader):\n",
    "    model.load_state_dict(torch.load(os.path.join(cacheDir, \"model_1.pth\")))\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        yhat, ghat = model(inputs)\n",
    "        metrics = compute_metrics(yhat, ghat, labels)\n",
    "        if i == 0:\n",
    "            all_metrics = metrics\n",
    "        else:\n",
    "            for key, val in metrics.items():\n",
    "                all_metrics[key] += val.item()\n",
    "    for key in all_metrics.keys():\n",
    "        all_metrics[key] /= len(test_loader)\n",
    "\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_metrics = evaluation(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss(yhat, ghat, batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "count_parameters(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
